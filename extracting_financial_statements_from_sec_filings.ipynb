{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "extracting-financial-statements-from-sec-filings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/production-engineer/earth-100/blob/main/extracting_financial_statements_from_sec_filings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting Financial Statements from SEC Filings - XBRL-To-JSON\n",
        "\n",
        "This is the entire Jupyter notebook to extract financial statements from annual and quarterly reports as reported in 10-K and 10-Q filings with the SEC.\n",
        "\n",
        "We use https://sec-api.io to get all 10-K and 10-Q filings and to convert their XBRL data into JSON so that we can create a single income statement, balance sheet and cash flow statement for Apple, covering quarterly financial data over multiple years.\n",
        "\n",
        "Medium article:\n",
        "https://medium.com/@jan_5421/extracting-financial-statements-from-sec-filings-xbrl-to-json-f83542ade90"
      ],
      "metadata": {
        "id": "on7oHdViSW-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment the next line to install the SEC API Python package\n",
        "%pip install sec_api"
      ],
      "metadata": {
        "id": "5EY1SvF8mgXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0de13f5-cc26-4900-9912-f75923244199"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sec_api\n",
            "  Downloading sec_api-1.0.9-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from sec_api) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->sec_api) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->sec_api) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->sec_api) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->sec_api) (2021.10.8)\n",
            "Installing collected packages: sec-api\n",
            "Successfully installed sec-api-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get your free API key at https://sec-api.io\n",
        "api_key = \"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "WvdIIMeUR4yn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "KLnnfR8Oi-FD",
        "outputId": "c5f3dc62-d86a-4238-ba26-c6df0ab004d8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1d59bae1f21d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# income statement example\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxbrl_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'StatementsOfIncome'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RevenueFromContractWithCustomerExcludingAssessedTax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'StatementsOfIncome'"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# 10-Q filing URL of Apple\n",
        "filing_url = \"https://www.sec.gov/Archives/edgar/data/320193/000032019321000056/aapl-20210327.htm\"\n",
        "\n",
        "# XBRL-to-JSON converter API endpoint\n",
        "xbrl_converter_api_endpoint = \"https://api.sec-api.io/xbrl-to-json\"\n",
        "\n",
        "final_url = xbrl_converter_api_endpoint + \"?htm-url=\" + filing_url + \"&token=\" + api_key\n",
        "\n",
        "# make request to the API\n",
        "response = requests.get(final_url)\n",
        "\n",
        "# load JSON into memory\n",
        "xbrl_json = json.loads(response.text)\n",
        "\n",
        "# income statement example\n",
        "print(json.dumps(xbrl_json['StatementsOfIncome']['RevenueFromContractWithCustomerExcludingAssessedTax'][0:2], indent=1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert XBRL-JSON of income statement to pandas dataframe\n",
        "def get_income_statement(xbrl_json):\n",
        "    income_statement_store = {}\n",
        "\n",
        "    # iterate over each US GAAP item in the income statement\n",
        "    for usGaapItem in xbrl_json['StatementsOfIncome']:\n",
        "        values = []\n",
        "        indicies = []\n",
        "\n",
        "        for fact in xbrl_json['StatementsOfIncome'][usGaapItem]:\n",
        "            # only consider items without segment. not required for our analysis.\n",
        "            if 'segment' not in fact:\n",
        "                index = fact['period']['startDate'] + '-' + fact['period']['endDate']\n",
        "                # ensure no index duplicates are created\n",
        "                if index not in indicies:\n",
        "                    values.append(fact['value'])\n",
        "                    indicies.append(index)                    \n",
        "\n",
        "        income_statement_store[usGaapItem] = pd.Series(values, index=indicies) \n",
        "\n",
        "    income_statement = pd.DataFrame(income_statement_store)\n",
        "    # switch columns and rows so that US GAAP items are rows and each column header represents a date range\n",
        "    return income_statement.T \n",
        "\n",
        "income_statement = get_income_statement(xbrl_json)"
      ],
      "metadata": {
        "id": "w3XdohlpjM7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "income_statement"
      ],
      "metadata": {
        "id": "YooC5Kihjg4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# convert XBRL-JSON of balance sheet to pandas dataframe\n",
        "def get_balance_sheet(xbrl_json):\n",
        "    balance_sheet_store = {}\n",
        "\n",
        "    for usGaapItem in xbrl_json['BalanceSheets']:\n",
        "        values = []\n",
        "        indicies = []\n",
        "\n",
        "        for fact in xbrl_json['BalanceSheets'][usGaapItem]:\n",
        "            # only consider items without segment.\n",
        "            if 'segment' not in fact:\n",
        "                index = fact['period']['instant']\n",
        "\n",
        "                # avoid duplicate indicies with same values\n",
        "                if index in indicies:\n",
        "                    continue\n",
        "                    \n",
        "                # add 0 if value is nil\n",
        "                if \"value\" not in fact:\n",
        "                    values.append(0)\n",
        "                else:\n",
        "                    values.append(fact['value'])\n",
        "\n",
        "                indicies.append(index)                    \n",
        "\n",
        "            balance_sheet_store[usGaapItem] = pd.Series(values, index=indicies) \n",
        "\n",
        "    balance_sheet = pd.DataFrame(balance_sheet_store)\n",
        "    # switch columns and rows so that US GAAP items are rows and each column header represents a date instant\n",
        "    return balance_sheet.T\n",
        "\n",
        "balance_sheet = get_balance_sheet(xbrl_json)"
      ],
      "metadata": {
        "id": "d2-J98Oijicy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_sheet"
      ],
      "metadata": {
        "id": "xyA2Ush-jog4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_cash_flow_statement(xbrl_json):\n",
        "    cash_flows_store = {}\n",
        "\n",
        "    for usGaapItem in xbrl_json['StatementsOfCashFlows']:\n",
        "        values = []\n",
        "        indicies = []\n",
        "\n",
        "        for fact in xbrl_json['StatementsOfCashFlows'][usGaapItem]:        \n",
        "            # only consider items without segment.\n",
        "            if 'segment' not in fact:\n",
        "                # check if date instant or date range is present\n",
        "                if \"instant\" in fact['period']:\n",
        "                    index = fact['period']['instant']\n",
        "                else:\n",
        "                    index = fact['period']['startDate'] + '-' + fact['period']['endDate']\n",
        "\n",
        "                # avoid duplicate indicies with same values\n",
        "                if index in indicies:\n",
        "                    continue\n",
        "\n",
        "                if \"value\" not in fact:\n",
        "                    values.append(0)\n",
        "                else:\n",
        "                    values.append(fact['value'])\n",
        "\n",
        "                indicies.append(index)                    \n",
        "\n",
        "        cash_flows_store[usGaapItem] = pd.Series(values, index=indicies) \n",
        "\n",
        "\n",
        "    cash_flows = pd.DataFrame(cash_flows_store)\n",
        "    return cash_flows.T\n",
        "    \n",
        "cash_flows = get_cash_flow_statement(xbrl_json)"
      ],
      "metadata": {
        "id": "iSO91uVgjptu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cash_flows"
      ],
      "metadata": {
        "id": "OZucISzYj2JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sec_api import QueryApi\n",
        "\n",
        "# get your API key at https://sec-api.io\n",
        "query_api = QueryApi(api_key=api_key)\n",
        "\n",
        "# fetch all 10-Q and 10-K filings for Apple\n",
        "query = {\n",
        "    \"query\": {\n",
        "        \"query_string\": {\n",
        "            \"query\": \"(formType:\\\"10-Q\\\" OR formType:\\\"10-K\\\") AND ticker:AAPL\"\n",
        "        }\n",
        "    },\n",
        "    \"from\": \"0\",\n",
        "    \"size\": \"20\",\n",
        "    \"sort\": [{ \"filedAt\": { \"order\": \"desc\" } }]\n",
        "}\n",
        "\n",
        "query_result = query_api.get_filings(query)"
      ],
      "metadata": {
        "id": "ZYvKrEthkJSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accession_numbers = []\n",
        "\n",
        "# extract accession numbers of each filing\n",
        "for filing in query_result['filings']:\n",
        "    accession_numbers.append(filing['accessionNo']);\n",
        "\n",
        "accession_numbers"
      ],
      "metadata": {
        "id": "6V-9o7IQkVNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# get XBRL-JSON for a given accession number\n",
        "def get_xbrl_json(accession_no, retry = 0):\n",
        "    request_url = xbrl_converter_api_endpoint + \"?accession-no=\" + accession_no + \"&token=\" + api_key\n",
        "\n",
        "    # linear backoff in case API fails with \"too many requests\" error\n",
        "    try:\n",
        "      response_tmp = requests.get(request_url)\n",
        "      xbrl_json = json.loads(response_tmp.text)\n",
        "    except:\n",
        "      if retry > 5:\n",
        "        raise Exception('API error')\n",
        "      \n",
        "      # wait 500 milliseconds on error and retry\n",
        "      time.sleep(0.5) \n",
        "      return get_xbrl_json(accession_no, retry + 1)\n",
        "\n",
        "    return xbrl_json"
      ],
      "metadata": {
        "id": "217wZdfnkdw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# clean income statement.\n",
        "# drop duplicate columns (= column name ends with \"_left\"), drop key_0 column, drop columns with +5 NaNs\n",
        "def clean_income_statement(statement):\n",
        "    for column in statement:\n",
        "\n",
        "        # column has more than 5 NaN values\n",
        "        is_nan_column = statement[column].isna().sum() > 5\n",
        "\n",
        "        if column.endswith('_left') or column == 'key_0' or is_nan_column:\n",
        "            statement = statement.drop(column, axis=1)\n",
        "    \n",
        "    # rearrange columns so that first column represents first quarter\n",
        "    # e.g. 2018, 2019, 2020 - and not 2020, 2019, 2018\n",
        "    sorted_columns = sorted(statement.columns.values)\n",
        "    \n",
        "    return statement[sorted_columns]"
      ],
      "metadata": {
        "id": "M_CrR8ISkiAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge two income statements into one statement.\n",
        "# row indicies of both statements have to be the same\n",
        "# statement_b represents the most recent statement.\n",
        "def merge_income_statements(statement_a, statement_b):\n",
        "    return statement_a.merge(statement_b,\n",
        "                     how=\"outer\", \n",
        "                    #  on=statement_b.index, \n",
        "                    right_on=statement_b.index, \n",
        "                     left_index=True,\n",
        "                    #  right_index=True,\n",
        "                     suffixes=('_left', ''))"
      ],
      "metadata": {
        "id": "KQm_3f5lkfnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# helps printing dataframes while we generate new income statement\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "previous_income_statement_set = False\n",
        "income_statement_final = None\n",
        "\n",
        "for accession_no in accession_numbers[0:12]:\n",
        "# for accession_no in accession_numbers: # doesn't work with filings filed before 2017 - indicies not equal\n",
        "    print('Processing: ' + accession_no)\n",
        "    \n",
        "    # get XBRL-JSON of 10-Q or 10-K filing by accession number\n",
        "    xbrl_json_data = get_xbrl_json(accession_no)\n",
        "    \n",
        "    # convert XBRL-JSON to a pandas dataframe\n",
        "    income_statement_uncleaned = get_income_statement(xbrl_json_data)\n",
        "\n",
        "    # clean the income statement\n",
        "    income_statement_cleaned = clean_income_statement(income_statement_uncleaned)\n",
        "    \n",
        "    # print income statement on each iteration to monitor progress\n",
        "    # display(HTML(income_statement_cleaned.to_html()))\n",
        "    \n",
        "    # merge new income statement with previously generated income statement\n",
        "    if previous_income_statement_set:\n",
        "        income_statement_final = clean_income_statement(merge_income_statements(income_statement_final, income_statement_cleaned))\n",
        "    else:\n",
        "        income_statement_final = income_statement_cleaned\n",
        "        previous_income_statement_set = True"
      ],
      "metadata": {
        "id": "F-5_i9kDkrwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "income_statement_final"
      ],
      "metadata": {
        "id": "eQ03kAQnxfp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# convert string to int or float\n",
        "def num(string):\n",
        "    try:\n",
        "        return int(string)\n",
        "    except ValueError:\n",
        "        return float(string)\n",
        "    \n",
        "# calculate 4th quarter results\n",
        "# 4th quarter results are not reported seperately and have to be calculated using yearly and 9-month results\n",
        "def add_fourth_quarter_results(statement):\n",
        "    for column in statement:\n",
        "\n",
        "        # ['2018', '09', '30', '2019', '09', '28']\n",
        "        date_strings = [a for a in column.split('-')] \n",
        "\n",
        "        d0 = datetime.strptime(date_strings[0] + date_strings[1] + date_strings[2], '%Y%m%d')\n",
        "        d1 = datetime.strptime(date_strings[3] + date_strings[4] + date_strings[5], '%Y%m%d')\n",
        "\n",
        "        delta = d1 - d0\n",
        "\n",
        "        # is annual results column\n",
        "        if delta.days > 350:\n",
        "            for column_1 in statement:\n",
        "                date_strings_1 = [a for a in column_1.split('-')]\n",
        "\n",
        "                d1_0 = datetime.strptime(date_strings_1[0] + date_strings_1[1] + date_strings_1[2], '%Y%m%d')\n",
        "                d1_1 = datetime.strptime(date_strings_1[3] + date_strings_1[4] + date_strings_1[5], '%Y%m%d')\n",
        "\n",
        "                delta_1 = d1_1 - d1_0\n",
        "\n",
        "                # same starting month and 9-month results\n",
        "                # calculate 4th quarter\n",
        "                if d1_0 == d0 and delta_1.days > 200 and delta_1.days < 350:\n",
        "                    fourth_quarter_column_name = column_1[11:] + column[10:]\n",
        "\n",
        "                    fourth_quarter_values = []\n",
        "\n",
        "                    for row_key, row_value in statement[column].iteritems():\n",
        "                        value = num(statement[column][row_key]) - num(statement[column_1][row_key])\n",
        "                        \n",
        "                        if isinstance(value, float):\n",
        "                            value = round(value, 2)\n",
        "            \n",
        "                        fourth_quarter_values.append(str(value))\n",
        "\n",
        "                    statement[fourth_quarter_column_name] = fourth_quarter_values\n",
        " \n",
        "                    # Calculate correct values of\n",
        "                    # WeightedAverageNumberOfSharesOutstandingBasic = use value of annual result\n",
        "                    # WeightedAverageNumberOfDilutedSharesOutstanding = use value of annual result\n",
        "                    # EarningsPerShareBasic = NetIncomeLoss / WeightedAverageNumberOfSharesOutstandingBasic\n",
        "                    # EarningsPerShareDiluted = NetIncomeLoss / WeightedAverageNumberOfDilutedSharesOutstanding\n",
        "                    statement[fourth_quarter_column_name][\"WeightedAverageNumberOfSharesOutstandingBasic\"] = statement[column][\"WeightedAverageNumberOfSharesOutstandingBasic\"]\n",
        "                    statement[fourth_quarter_column_name][\"WeightedAverageNumberOfDilutedSharesOutstanding\"] = statement[column][\"WeightedAverageNumberOfDilutedSharesOutstanding\"]\n",
        "\n",
        "                    statement[fourth_quarter_column_name][\"EarningsPerShareBasic\"] = round(num(statement[fourth_quarter_column_name][\"NetIncomeLoss\"]) / \n",
        "                                                                                         num(statement[fourth_quarter_column_name][\"WeightedAverageNumberOfSharesOutstandingBasic\"]), 2)\n",
        "                    \n",
        "                    statement[fourth_quarter_column_name][\"EarningsPerShareDiluted\"] = round(num(statement[fourth_quarter_column_name][\"NetIncomeLoss\"]) / \n",
        "                                                                                         num(statement[fourth_quarter_column_name][\"WeightedAverageNumberOfDilutedSharesOutstanding\"]), 2)\n",
        "                \n",
        "    # sort columns\n",
        "    sorted_columns = sorted(statement.columns.values)\n",
        "    \n",
        "    return statement[sorted_columns]"
      ],
      "metadata": {
        "id": "V34P7ptkkuRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statement = income_statement_final\n",
        "statement_1 = add_fourth_quarter_results(statement)"
      ],
      "metadata": {
        "id": "eQrdYzjzu_0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "statement_1"
      ],
      "metadata": {
        "id": "olTvx_U_vIir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove all non-quarterly columns\n",
        "def only_quarterly_results(statement):\n",
        "    for column in statement:\n",
        "        # convert all strings to int\n",
        "        date_strings = [a for a in column.split('-')]\n",
        "\n",
        "        d0 = datetime.strptime(date_strings[0] + date_strings[1] + date_strings[2], '%Y%m%d')\n",
        "        d1 = datetime.strptime(date_strings[3] + date_strings[4] + date_strings[5], '%Y%m%d')\n",
        "        delta = d1 - d0\n",
        "\n",
        "        # column represents more timeframe longer than one quarter\n",
        "        if delta.days > 100:\n",
        "            statement = statement.drop(column, axis=1)\n",
        "    return statement"
      ],
      "metadata": {
        "id": "6WPsPmzkuSCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qrt_income_statement = only_quarterly_results(statement_1)\n",
        "qrt_income_statement"
      ],
      "metadata": {
        "id": "kc2T0ETSuTnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as tick\n",
        "import numpy as np\n",
        "\n",
        "# custom y axis formatter\n",
        "def format_dollars(y, pos=None):\n",
        "    return int(y/1000000000)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "\n",
        "ax = qrt_income_statement.astype(float)\\\n",
        "                         .loc[\"NetIncomeLoss\"]\\\n",
        "                         .plot.line(legend=True)\n",
        "ax = qrt_income_statement.astype(float)\\\n",
        "                         .loc[\"RevenueFromContractWithCustomerExcludingAssessedTax\"]\\\n",
        "                         .plot.line(legend=True)\n",
        "\n",
        "ax.set_title('Quarterly Revenues and Net Income')\n",
        "\n",
        "ax.yaxis.set_major_formatter(tick.FuncFormatter(format_dollars))\n",
        "\n",
        "plt.ylabel('$ Billions')\n",
        "\n",
        "# show all quarter date ranges\n",
        "plt.xticks(ticks=np.arange(len(qrt_income_statement.columns)),\n",
        "           labels=qrt_income_statement.columns)\n",
        "\n",
        "# format x axis properly\n",
        "fig.autofmt_xdate()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UAeN4pEKy2ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.ticker import FormatStrFormatter\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
        "\n",
        "ax = qrt_income_statement.astype(float).loc[\"EarningsPerShareBasic\"].plot.line()\n",
        "\n",
        "ax.set_title('Earnings Per Share Basic')\n",
        "\n",
        "# use higher precision for y axis labels\n",
        "ax.yaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
        "\n",
        "plt.xticks(ticks=np.arange(len(qrt_income_statement.columns)),\n",
        "           labels=qrt_income_statement.columns)\n",
        "\n",
        "# format x axis properly\n",
        "fig.autofmt_xdate()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqE2gGKRzP8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MdI0mDyEzeTi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}